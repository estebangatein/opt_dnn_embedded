{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 16:36:10.070503: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733412970.084263   24936 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733412970.088428   24936 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-05 16:36:10.102203: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import accuracy_score\n",
    "from keras.layers import TFSMLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tflite_size = os.path.getsize('qat_model.tflite')/(1024**2)\n",
    "model_original_size = sum(os.path.getsize(os.path.join(dirpath, filename)) for dirpath, _, filenames in os.walk('original_model') for filename in filenames)/(1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model size: 119.30 MB\n",
      "Quantized model size: 9.91 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original model size: {model_original_size:.2f} MB\")\n",
    "print(f\"Quantized model size: {model_tflite_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference time\n",
    "\n",
    "Time for inference to compare the QAT model vs. the original one has been executed on the same device with CPUs, note that the time on GAP9 may be different. The test was executed through the time_test.py script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model mean time per inference: 30.58 ms\n",
      "Quantized model mean time per inference: 13.99 ms\n"
     ]
    }
   ],
   "source": [
    "print('Original model mean time per inference: 30.58 ms')\n",
    "print('Quantized model mean time per inference: 13.99 ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_creator(path_to_folder, max_by_experiment = 3):\n",
    "    col, fire, steer = 0, 0, 0\n",
    "    images, labels = [], []\n",
    "\n",
    "    for folder in os.listdir(path_to_folder):\n",
    "\n",
    "        if os.path.isdir(os.path.join(path_to_folder, folder)):\n",
    "\n",
    "            for file in os.listdir(os.path.join(path_to_folder, folder)):\n",
    "\n",
    "                if file.endswith('.txt'):\n",
    "                    if 'labels' in file and col < max_by_experiment:\n",
    "                        col += 1\n",
    "                        for pic in sorted(os.listdir(os.path.join(path_to_folder, folder, 'images'))):\n",
    "                            img = load_img(os.path.join(os.path.join(path_to_folder, folder, 'images'), pic), target_size=(200, 200), color_mode='grayscale')  # Ajustar tamaño y modo de color\n",
    "                            img_array = img_to_array(img) / 255.0  # Normalizar la imagen\n",
    "                            images.append(img_array)\n",
    "                        \n",
    "                        labels_txt = np.loadtxt(os.path.join(path_to_folder, folder, file))\n",
    "\n",
    "                        for label in labels_txt:\n",
    "                            if label == 0:\n",
    "                                label = [np.array([1, 0]), np.array([np.nan]*4), np.array([np.nan])]\n",
    "                            elif label == 1:\n",
    "                                label = [np.array([0, 1]), np.array([np.nan]*4), np.array([np.nan])]\n",
    "                            label = pad_sequences(label, dtype='float32', padding='post', value=np.nan)\n",
    "                            labels.append(label)\n",
    "\n",
    "\n",
    "                    elif 'fire' in file and fire < max_by_experiment:\n",
    "                        fire += 1\n",
    "                        for pic in sorted(os.listdir(os.path.join(path_to_folder, folder, 'images'))):\n",
    "                            img = load_img(os.path.join(os.path.join(path_to_folder, folder, 'images'), pic), target_size=(200, 200), color_mode='grayscale')  # Ajustar tamaño y modo de color\n",
    "                            img_array = img_to_array(img) / 255.0  # Normalizar la imagen\n",
    "                            images.append(img_array)\n",
    "                        \n",
    "                        labels_txt = np.loadtxt(os.path.join(path_to_folder, folder, file), delimiter=' ')\n",
    "\n",
    "                        for label in labels_txt:\n",
    "                            label = [np.array([np.nan]*2), label, np.array([np.nan])]\n",
    "                            label = pad_sequences(label, dtype='float32', padding='post', value=np.nan)\n",
    "                            labels.append(label)\n",
    "\n",
    "                            \n",
    "                    elif 'sync' in file and steer < max_by_experiment:\n",
    "                        steer += 1\n",
    "                        for pic in sorted(os.listdir(os.path.join(path_to_folder, folder, 'images'))):\n",
    "                            img = load_img(os.path.join(os.path.join(path_to_folder, folder, 'images'), pic), target_size=(200, 200), color_mode='grayscale')\n",
    "                            img_array = img_to_array(img) / 255.0\n",
    "                            images.append(img_array)\n",
    "\n",
    "                        labels_txt = np.loadtxt(os.path.join(path_to_folder, folder, file), usecols=0, delimiter=',', skiprows=1)\n",
    "\n",
    "                        for label in labels_txt:\n",
    "                            label = [np.array([np.nan]*2), np.array([np.nan]*4), np.array([label])]\n",
    "                            label = pad_sequences(label, dtype='float32', padding='post', value=np.nan)\n",
    "                            labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images_test, labels_test = dataset_creator('../../testing', 5)\n",
    "indices = np.random.permutation(images_test.shape[0])\n",
    "images_test = images_test[indices]\n",
    "labels_test = labels_test[indices]\n",
    "y_col_test, y_fire_test, y_steer_test = labels_test[:,0, :][:, :2], labels_test[:, 1, :], labels_test[:, 2, :][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-05 16:36:37.005713: E external/local_xla/xla/stream_executor/cuda/cuda_driver.cc:152] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión clasificador binario (original): 0.7709637046307884\n",
      "Precisión clasificador multiclase (original): 0.7940436241610739\n",
      "Precisión regresión (original): 0.18170204758644104\n",
      "Precisión clasificador binario (quantizado): 0.9136420525657072\n",
      "Precisión clasificador multiclase (quantizado): 0.738255033557047\n",
      "Precisión regresión (quantizado): 0.2646496891975403\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Función para calcular precisión en tareas de clasificación\n",
    "def calculate_classification_precision(predictions, labels):\n",
    "    # Aplicar argmax a las predicciones y etiquetas para obtener la clase predicha\n",
    "    if predictions.ndim == 2:  # Para clasificación binaria o multiclase\n",
    "        predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    if labels.ndim == 2:  # Para clasificación binaria o multiclase\n",
    "        labels = np.argmax(labels, axis=1)\n",
    "\n",
    "    # Asegurarnos de que las etiquetas no tengan NaN\n",
    "    valid_indices = ~np.isnan(labels)  # Indices donde el label no es NaN\n",
    "    valid_labels = labels[valid_indices]\n",
    "    valid_predictions = predictions[valid_indices]\n",
    "    \n",
    "    # Calcular la precisión\n",
    "    accuracy = accuracy_score(valid_labels, valid_predictions)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "# Función para calcular el error absoluto medio (para la regresión)\n",
    "def calculate_regression_precision(predictions, labels):\n",
    "    valid_indices = ~np.isnan(labels)  # Indices donde el label no es NaN\n",
    "    valid_labels = labels[valid_indices]\n",
    "    valid_predictions = predictions[valid_indices]\n",
    "    \n",
    "    # Calcular el error absoluto medio para la regresión\n",
    "    mae = np.mean(np.abs(valid_predictions - valid_labels))\n",
    "    return mae\n",
    "\n",
    "# Función para evaluar el modelo normal (no quantizado) en cada tarea\n",
    "def evaluate_model_normal(model, images, labels_bin, labels_multiclass, labels_reg):\n",
    "    predictions_bin = []\n",
    "    predictions_multiclass = []\n",
    "    predictions_reg = []\n",
    "\n",
    "    # Iterar sobre las imágenes\n",
    "    for img in images:\n",
    "        pred = model(tf.expand_dims(img, axis=0))  # Expandir dimensión para batch de tamaño 1\n",
    "\n",
    "        # Aquí procesamos la salida, que es un diccionario\n",
    "        class_1_pred = pred['labels_output'].numpy()  # Clasificador binario\n",
    "        class_2_pred = pred['fire_output'].numpy()  # Clasificador multiclase\n",
    "        reg_pred = pred['steering_output'].numpy()  # Regresión\n",
    "\n",
    "        # Aplanar las predicciones de cada tarea\n",
    "        predictions_bin.append(class_1_pred.flatten())  # Clasificación binaria\n",
    "        predictions_multiclass.append(class_2_pred.flatten())  # Clasificación multiclase\n",
    "        predictions_reg.append(reg_pred.flatten())  # Regresión\n",
    "\n",
    "    # Convertir las predicciones a numpy para calcular la precisión\n",
    "    predictions_bin = np.array(predictions_bin)\n",
    "    predictions_multiclass = np.array(predictions_multiclass)\n",
    "    predictions_reg = np.array(predictions_reg)\n",
    "\n",
    "    # Filtrar índices válidos para cada tarea\n",
    "    valid_indices_bin = ~np.isnan(labels_bin[:, 0])  # Índices válidos para clasificación binaria\n",
    "    valid_indices_multiclass = ~np.isnan(labels_multiclass[:, 0])  # Índices válidos para clasificación multiclase\n",
    "    valid_indices_reg = ~np.isnan(labels_reg)  # Índices válidos para regresión\n",
    "\n",
    "    # Aplicar el filtrado a las predicciones y etiquetas\n",
    "    predictions_bin = predictions_bin[valid_indices_bin]\n",
    "    labels_bin = labels_bin[valid_indices_bin]\n",
    "\n",
    "    predictions_multiclass = predictions_multiclass[valid_indices_multiclass]\n",
    "    labels_multiclass = labels_multiclass[valid_indices_multiclass]\n",
    "\n",
    "    predictions_reg = predictions_reg[valid_indices_reg]\n",
    "    labels_reg = labels_reg[valid_indices_reg]\n",
    "\n",
    "    # Calcular la precisión para la clasificación binaria\n",
    "    accuracy_bin = calculate_classification_precision(predictions_bin, labels_bin)\n",
    "\n",
    "    # Calcular la precisión para la clasificación multiclase\n",
    "    accuracy_multiclass = calculate_classification_precision(predictions_multiclass, labels_multiclass)\n",
    "\n",
    "    # Calcular la precisión para la regresión (error absoluto medio)\n",
    "    regression_precision = calculate_regression_precision(predictions_reg, labels_reg)\n",
    "\n",
    "    return accuracy_bin, accuracy_multiclass, regression_precision\n",
    "\n",
    "# Función para evaluar el modelo quantizado (TFLite) en cada tarea\n",
    "def evaluate_model_quantized(tflite_path, images, labels_bin, labels_multiclass, labels_reg):\n",
    "    # Cargar el modelo TFLite\n",
    "    interpreter = tf.lite.Interpreter(model_path=tflite_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Obtener detalles de entrada y salida\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "\n",
    "    predictions_bin = []\n",
    "    predictions_multiclass = []\n",
    "    predictions_reg = []\n",
    "\n",
    "    # Iterar sobre las imágenes\n",
    "    for img in images:\n",
    "        # Preparar entrada\n",
    "        input_data = tf.expand_dims(img, axis=0).numpy().astype(input_details[0]['dtype'])\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "\n",
    "        interpreter.invoke()  # Ejecutar inferencia\n",
    "\n",
    "        # Extraer las predicciones para cada salida\n",
    "        outputs = [interpreter.get_tensor(output['index']) for output in output_details]\n",
    "        \n",
    "        # Aplanar las salidas para cada tarea (por ejemplo, 'labels_output', 'fire_output', 'steering_output')\n",
    "        predictions_bin.append(outputs[2].flatten())  # Clasificación binaria\n",
    "        predictions_multiclass.append(outputs[0].flatten())  # Clasificación multiclase\n",
    "        predictions_reg.append(outputs[1].flatten())  # Regresión\n",
    "\n",
    "    # Convertir las predicciones a numpy para calcular la precisión\n",
    "    predictions_bin = np.array(predictions_bin)\n",
    "    predictions_multiclass = np.array(predictions_multiclass)\n",
    "    predictions_reg = np.array(predictions_reg)\n",
    "\n",
    "    # Calcular la precisión para la clasificación binaria\n",
    "    valid_indices_bin = ~np.isnan(labels_bin[:, 0])\n",
    "    valid_indices_multiclass = ~np.isnan(labels_multiclass[:, 0])\n",
    "    valid_indices_reg = ~np.isnan(labels_reg)\n",
    "\n",
    "    accuracy_bin = calculate_classification_precision(predictions_bin[valid_indices_bin], labels_bin[valid_indices_bin])\n",
    "    accuracy_multiclass = calculate_classification_precision(predictions_multiclass[valid_indices_multiclass], labels_multiclass[valid_indices_multiclass])\n",
    "    regression_precision = calculate_regression_precision(predictions_reg[valid_indices_reg], labels_reg[valid_indices_reg])\n",
    "\n",
    "    return accuracy_bin, accuracy_multiclass, regression_precision\n",
    "\n",
    "\n",
    "# Cargar el modelo original (sin quantizar)\n",
    "model = TFSMLayer('original_model', call_endpoint='serving_default')  # Asegúrate de que el modelo se cargue correctamente\n",
    "\n",
    "# Evaluar el modelo original\n",
    "accuracy_bin, accuracy_multiclass, regression_precision = evaluate_model_normal(\n",
    "    model, images_test, y_col_test, y_fire_test, y_steer_test\n",
    ")\n",
    "\n",
    "# Evaluar el modelo quantizado\n",
    "tflite_path = 'qat_model.tflite'  # Ruta a tu modelo quantizado en formato TFLite\n",
    "accuracy_bin_qat, accuracy_multiclass_qat, regression_precision_qat = evaluate_model_quantized(\n",
    "    tflite_path, images_test, y_col_test, y_fire_test, y_steer_test\n",
    ")\n",
    "\n",
    "# Imprimir resultados\n",
    "print(f\"Precisión clasificador binario (original): {accuracy_bin}\")\n",
    "print(f\"Precisión clasificador multiclase (original): {accuracy_multiclass}\")\n",
    "print(f\"Precisión regresión (original): {regression_precision}\")\n",
    "\n",
    "print(f\"Precisión clasificador binario (quantizado): {accuracy_bin_qat}\")\n",
    "print(f\"Precisión clasificador multiclase (quantizado): {accuracy_multiclass_qat}\")\n",
    "print(f\"Precisión regresión (quantizado): {regression_precision_qat}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Metric': ['Collision accuracy', 'Fire detection accuracy', 'Steering angle MSE', 'Number of epochs'],\n",
    "               'Original model':[accuracy_bin, accuracy_multiclass, regression_precision, 21], \n",
    "              'QAT model': [accuracy_bin_qat, accuracy_multiclass_qat, regression_precision_qat, 45]}).to_csv('performance_table.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
