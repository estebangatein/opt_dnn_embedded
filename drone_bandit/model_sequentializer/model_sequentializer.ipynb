{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to build a simple tree structure\n",
    "class Node:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.children = []\n",
    "\n",
    "    def add_child(self, child):\n",
    "        self.children.append(child)\n",
    "\n",
    "# function to get the node with a specific name\n",
    "def get_node(root, name):\n",
    "    if root.name == name:\n",
    "        return root\n",
    "    for child in root.children:\n",
    "        result = get_node(child, name)\n",
    "        if result:\n",
    "            return result\n",
    "\n",
    "# function to get a branch of the tree\n",
    "def get_branch(node):\n",
    "    if len(node.children) == 0:\n",
    "        if 'softmax' in node.name:\n",
    "            return [None]\n",
    "        else:\n",
    "            return [node.name]\n",
    "        \n",
    "    elif len(node.children) == 1:\n",
    "        return [node.name] + get_branch(node.children[0])\n",
    "    else:\n",
    "        return [node.name] + node.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_model(model):\n",
    "    \n",
    "    # transforms a fully functional model to a model formed by sequential models\n",
    "\n",
    "    def visualize_model(model):\n",
    "        # traces the execution of the model\n",
    "        tracer = torch.fx.Tracer()\n",
    "        graph = tracer.trace(model)\n",
    "\n",
    "        # obtains a summary of the model\n",
    "        graph_info = []\n",
    "        for node in graph.nodes:\n",
    "            node_info = {\n",
    "                'name': node.name,\n",
    "                'op': node.op,\n",
    "                'target': str(node.target),\n",
    "                'args': [str(arg) for arg in node.args],\n",
    "                'kwargs': node.kwargs,\n",
    "                'users': node.users\n",
    "            }\n",
    "            graph_info.append(node_info)\n",
    "\n",
    "        return graph_info\n",
    "    \n",
    "    graph_info = visualize_model(model)\n",
    "\n",
    "    # initializes the root node\n",
    "    root = Node(graph_info[0]['name'])\n",
    "    visited = [graph_info[0]['name']]\n",
    "\n",
    "    # builds the tree structure\n",
    "    for layer in graph_info[1:]:\n",
    "        parent = get_node(root, layer['args'][0])\n",
    "        for arg in layer['args']:\n",
    "            if arg in visited:\n",
    "                visited.append(layer['name'])\n",
    "                parent.add_child(Node(layer['name']))\n",
    "\n",
    "    # function that creates a partial representation of the model from the tree\n",
    "    def create_model(node):\n",
    "        start = get_branch(node)\n",
    "\n",
    "        model_partial = [nn.Sequential()]\n",
    "        for layer in start:\n",
    "            if layer == 'x':\n",
    "                continue\n",
    "\n",
    "            if not isinstance(layer, Node) and layer is not None and 'relu' not in layer and 'flatten' not in layer:\n",
    "                if isinstance(model_partial[-1], torch.nn.Flatten):\n",
    "                    model_partial.append(nn.Sequential())\n",
    "                model_partial[-1].add_module(layer, getattr(model, layer))\n",
    "\n",
    "            elif not isinstance(layer, Node) and layer is not None and 'flatten' in layer:\n",
    "                model_partial.append(nn.Flatten())\n",
    "                \n",
    "            elif not isinstance(layer, Node) and layer is not None and 'relu' in layer:\n",
    "                model_partial[-1].add_module('relu', nn.ReLU())\n",
    "\n",
    "            elif layer is None:\n",
    "                return model_partial\n",
    "            \n",
    "            elif isinstance(layer, Node):\n",
    "                model_partial.append(create_model(layer))\n",
    "\n",
    "        return model_partial\n",
    "\n",
    "    list_to_gen = create_model(root)\n",
    "\n",
    "    write_blocks = {}\n",
    "    write_forwards = {}\n",
    "\n",
    "    # function that counts elements recursively\n",
    "    def count_elements(lista):\n",
    "        total = 0\n",
    "        for elemento in lista:\n",
    "            if isinstance(elemento, list): \n",
    "                total += count_elements(elemento)\n",
    "            else:\n",
    "                total += 1  \n",
    "        return total\n",
    "\n",
    "    num_elements = list(range(count_elements(list_to_gen)))\n",
    "\n",
    "    # functions that will create the code structure\n",
    "    def write_block(list_to_gen):\n",
    "        for block in list_to_gen:\n",
    "            if isinstance(block, list):\n",
    "                write_block(block)\n",
    "            else:\n",
    "                write_blocks[num_elements.pop(0)] = block\n",
    "\n",
    "    write_block(list_to_gen)\n",
    "    num_elements = list(range(count_elements(list_to_gen)))\n",
    "\n",
    "    def write_forward(list_to_gen, parent=None):\n",
    "        for block in list_to_gen:\n",
    "            if isinstance(block, list):\n",
    "\n",
    "                list_to_gen = list_to_gen[list_to_gen.index(block):]\n",
    "                for following_list in list_to_gen:\n",
    "                    write_forward(following_list, parent)\n",
    "            \n",
    "                break\n",
    "\n",
    "\n",
    "            elif isinstance(block, nn.Flatten):\n",
    "                \n",
    "                write_forwards[num_elements[0]] = f'flatten_{parent}'\n",
    "                parent = num_elements[0]\n",
    "                num_elements.pop(0)\n",
    "\n",
    "            else:\n",
    "                \n",
    "                if block == list_to_gen[-1]:\n",
    "                    write_forwards[num_elements[0]] = f'output_sequential_{parent}'\n",
    "                    parent = num_elements[0]\n",
    "                    num_elements.pop(0)\n",
    "                else:\n",
    "                    write_forwards[num_elements[0]] = f'sequential_{parent}'\n",
    "                    parent = num_elements[0]\n",
    "                    num_elements.pop(0)\n",
    "\n",
    "\n",
    "    write_forward(list_to_gen)\n",
    "\n",
    "    # function that will generate the code\n",
    "    def generate_model_code(blocks_dict, forward_dict, filename=\"generated_model.py\"):\n",
    "   \n",
    "        with open(filename, \"w\") as f:\n",
    "\n",
    "            f.write(\"import torch\\n\")\n",
    "            f.write(\"import torch.nn as nn\\n\\n\")\n",
    "            f.write(\"class GeneratedModel(nn.Module):\\n\")\n",
    "            f.write(\"    def __init__(self):\\n\")\n",
    "            f.write(\"        super(GeneratedModel, self).__init__()\\n\\n\")\n",
    "            \n",
    "            # block definitions\n",
    "            for block_id, block in blocks_dict.items():\n",
    "                if not isinstance(block, nn.Flatten):  \n",
    "                    if isinstance(block, nn.Sequential):\n",
    "                        layers = [\n",
    "                            f\"nn.{str(layer)}\" \n",
    "                            for layer in block\n",
    "                        ]\n",
    "                        block_code = f\"nn.Sequential(\\n            \" + \",\\n            \".join(layers) + \"\\n        )\"\n",
    "                    else:\n",
    "                        block_code = f\"nn.{str(block)}\"\n",
    "                    \n",
    "                    f.write(f\"        self.block_{block_id} = {block_code}\\n\\n\")\n",
    "            \n",
    "\n",
    "            f.write(\"    def forward(self, x):\\n\")\n",
    "            \n",
    "            outputs = [] \n",
    "            for key, value in forward_dict.items():\n",
    "                parts = value.split(\"_\")\n",
    "                block_type = parts[0]\n",
    "                connection = parts[-1] \n",
    "                \n",
    "\n",
    "                if connection == \"None\":\n",
    "                    input_var = \"x\"\n",
    "                else:\n",
    "                    input_var = f\"out_{connection}\"\n",
    "                \n",
    "\n",
    "                if isinstance(blocks_dict[key], nn.Flatten):\n",
    "                    flatten_params = blocks_dict[key]\n",
    "                    f.write(f\"        out_{key} = {input_var}.flatten(start_dim={flatten_params.start_dim}, end_dim={flatten_params.end_dim})\\n\")\n",
    "                else:\n",
    "                    f.write(f\"        out_{key} = self.block_{key}({input_var})\\n\")\n",
    "                \n",
    "                if block_type == \"output\":\n",
    "                    outputs.append(f\"out_{key}\")\n",
    "            \n",
    "            if outputs:\n",
    "                if len(outputs) > 1:\n",
    "                    outputs_list = \", \".join(outputs)\n",
    "                    f.write(f\"        return {outputs_list}\\n\")\n",
    "                else:\n",
    "                    f.write(f\"        return {outputs[0]}\\n\")\n",
    "            else:\n",
    "                f.write(\"        return None\\n\")\n",
    "        \n",
    "        print(f\"Model generated and saved in {filename}\")\n",
    "    \n",
    "    generate_model_code(write_blocks, write_forwards)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OneEE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OneEE, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(256)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # early exit block\n",
    "        self.obj_detect_conv = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.obj_detect_bn = nn.BatchNorm2d(128)\n",
    "        self.obj_detect_fc_ee = nn.Linear(128 * 50 * 50, 4)  \n",
    "\n",
    "        self.conv5 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(512)\n",
    "        self.conv6 = nn.Conv2d(512, 512, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(512)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.obj_detect_fc_final = nn.Linear(512 * 25 * 25, 4)\n",
    "\n",
    "        self.binary_fc1 = nn.Linear(512 * 25 * 25, 256)\n",
    "        self.binary_fc2 = nn.Linear(256, 2)\n",
    "\n",
    "        self.regression_fc1 = nn.Linear(512 * 25 * 25, 256)\n",
    "        self.regression_fc2 = nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        x = F.relu(self.bn4(self.conv4(x)))\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        obj_detect_ee = F.relu(self.obj_detect_bn(self.obj_detect_conv(x)))\n",
    "        obj_detect_ee = torch.flatten(obj_detect_ee, 1)  # Aplanar\n",
    "        obj_detect_ee = F.softmax(self.obj_detect_fc_ee(obj_detect_ee), dim=1)\n",
    "\n",
    "        x = F.relu(self.bn5(self.conv5(x)))\n",
    "        x = F.relu(self.bn6(self.conv6(x)))\n",
    "        x = self.pool3(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        obj_detect_final = F.softmax(self.obj_detect_fc_final(x), dim=1)\n",
    "\n",
    "        binary_output = F.relu(self.binary_fc1(x))\n",
    "        binary_output = F.softmax(self.binary_fc2(binary_output), dim=1)\n",
    "\n",
    "        regression_output = F.relu(self.regression_fc1(x))\n",
    "        regression_output = self.regression_fc2(regression_output)\n",
    "\n",
    "        return obj_detect_ee, obj_detect_final, binary_output, regression_output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model generated and saved in generated_model.py\n"
     ]
    }
   ],
   "source": [
    "model = OneEE()\n",
    "seq_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if the model is defined as expected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 200, 200]             320\n",
      "       BatchNorm2d-2         [-1, 32, 200, 200]              64\n",
      "              ReLU-3         [-1, 32, 200, 200]               0\n",
      "            Conv2d-4         [-1, 64, 200, 200]          18,496\n",
      "       BatchNorm2d-5         [-1, 64, 200, 200]             128\n",
      "         MaxPool2d-6         [-1, 64, 100, 100]               0\n",
      "            Conv2d-7        [-1, 128, 100, 100]          73,856\n",
      "       BatchNorm2d-8        [-1, 128, 100, 100]             256\n",
      "            Conv2d-9        [-1, 256, 100, 100]         295,168\n",
      "      BatchNorm2d-10        [-1, 256, 100, 100]             512\n",
      "        MaxPool2d-11          [-1, 256, 50, 50]               0\n",
      "           Conv2d-12          [-1, 128, 50, 50]         295,040\n",
      "      BatchNorm2d-13          [-1, 128, 50, 50]             256\n",
      "             ReLU-14          [-1, 128, 50, 50]               0\n",
      "           Linear-15                    [-1, 4]       1,280,004\n",
      "           Conv2d-16          [-1, 512, 50, 50]       1,180,160\n",
      "      BatchNorm2d-17          [-1, 512, 50, 50]           1,024\n",
      "             ReLU-18          [-1, 512, 50, 50]               0\n",
      "           Conv2d-19          [-1, 512, 50, 50]       2,359,808\n",
      "      BatchNorm2d-20          [-1, 512, 50, 50]           1,024\n",
      "        MaxPool2d-21          [-1, 512, 25, 25]               0\n",
      "           Linear-22                    [-1, 4]       1,280,004\n",
      "           Linear-23                  [-1, 256]      81,920,256\n",
      "             ReLU-24                  [-1, 256]               0\n",
      "           Linear-25                    [-1, 2]             514\n",
      "           Linear-26                  [-1, 256]      81,920,256\n",
      "             ReLU-27                  [-1, 256]               0\n",
      "           Linear-28                    [-1, 1]             257\n",
      "================================================================\n",
      "Total params: 170,627,403\n",
      "Trainable params: 170,627,403\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.15\n",
      "Forward/backward pass size (MB): 195.32\n",
      "Params size (MB): 650.89\n",
      "Estimated Total Size (MB): 846.36\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from generated_model import GeneratedModel\n",
    "\n",
    "model = GeneratedModel()\n",
    "summary(model, (1, 200, 200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeneratedModel(\n",
      "  (block_0): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block_1): Sequential(\n",
      "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "  )\n",
      "  (block_3): Sequential(\n",
      "    (0): Linear(in_features=320000, out_features=4, bias=True)\n",
      "  )\n",
      "  (block_4): Sequential(\n",
      "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (block_6): Sequential(\n",
      "    (0): Linear(in_features=320000, out_features=4, bias=True)\n",
      "  )\n",
      "  (block_7): Sequential(\n",
      "    (0): Linear(in_features=320000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=2, bias=True)\n",
      "  )\n",
      "  (block_8): Sequential(\n",
      "    (0): Linear(in_features=320000, out_features=256, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=256, out_features=1, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
