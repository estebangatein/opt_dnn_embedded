{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model import TwoEE\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import os\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import onnxruntime as ort\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_creator(path_to_folder, max_by_experiment = 3):\n",
    "    col, fire, steer = 0, 0, 0\n",
    "    images, labels = [], []\n",
    "\n",
    "    for folder in os.listdir(path_to_folder):\n",
    "\n",
    "        if os.path.isdir(os.path.join(path_to_folder, folder)):\n",
    "\n",
    "            for file in os.listdir(os.path.join(path_to_folder, folder)):\n",
    "\n",
    "                if file.endswith('.txt'):\n",
    "                    if 'labels' in file and col < max_by_experiment:\n",
    "                        col += 1\n",
    "                        for pic in sorted(os.listdir(os.path.join(path_to_folder, folder, 'images'))):\n",
    "                            img = load_img(os.path.join(os.path.join(path_to_folder, folder, 'images'), pic), target_size=(200, 200), color_mode='grayscale')  # Ajustar tamaño y modo de color\n",
    "                            img_array = img_to_array(img) / 128.0 -1 # Normalizar la imagen\n",
    "                            images.append(img_array)\n",
    "                        \n",
    "                        labels_txt = np.loadtxt(os.path.join(path_to_folder, folder, file))\n",
    "\n",
    "                        for label in labels_txt:\n",
    "                            if label == 0:\n",
    "                                label = [np.array([1, 0]), np.array([np.nan]*4), np.array([np.nan])]\n",
    "                            elif label == 1:\n",
    "                                label = [np.array([0, 1]), np.array([np.nan]*4), np.array([np.nan])]\n",
    "                            label = pad_sequences(label, dtype='float32', padding='post', value=np.nan)\n",
    "                            labels.append(label)\n",
    "\n",
    "\n",
    "                    elif 'fire' in file and fire < max_by_experiment:\n",
    "                        fire += 1\n",
    "                        for pic in sorted(os.listdir(os.path.join(path_to_folder, folder, 'images'))):\n",
    "                            img = load_img(os.path.join(os.path.join(path_to_folder, folder, 'images'), pic), target_size=(200, 200), color_mode='grayscale')  # Ajustar tamaño y modo de color\n",
    "                            img_array = img_to_array(img) / 128.0 -1  # Normalizar la imagen\n",
    "                            images.append(img_array)\n",
    "                        \n",
    "                        labels_txt = np.loadtxt(os.path.join(path_to_folder, folder, file), delimiter=' ')\n",
    "\n",
    "                        for label in labels_txt:\n",
    "                            label = [np.array([np.nan]*2), label, np.array([np.nan])]\n",
    "                            label = pad_sequences(label, dtype='float32', padding='post', value=np.nan)\n",
    "                            labels.append(label)\n",
    "\n",
    "                            \n",
    "                    elif 'sync' in file and steer < max_by_experiment:\n",
    "                        steer += 1\n",
    "                        for pic in sorted(os.listdir(os.path.join(path_to_folder, folder, 'images'))):\n",
    "                            img = load_img(os.path.join(os.path.join(path_to_folder, folder, 'images'), pic), target_size=(200, 200), color_mode='grayscale')\n",
    "                            img_array = img_to_array(img) / 128.0 - 1\n",
    "                            images.append(img_array)\n",
    "\n",
    "                        labels_txt = np.loadtxt(os.path.join(path_to_folder, folder, file), usecols=0, delimiter=',', skiprows=1)\n",
    "\n",
    "                        for label in labels_txt:\n",
    "                            label = [np.array([np.nan]*2), np.array([np.nan]*4), np.array([label])]\n",
    "                            label = pad_sequences(label, dtype='float32', padding='post', value=np.nan)\n",
    "                            labels.append(label)\n",
    "\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "images_test, labels_test = dataset_creator('../../../testing', 5)\n",
    "indices = np.random.permutation(images_test.shape[0])\n",
    "images_test = images_test[indices]\n",
    "images_test = torch.tensor(images_test).permute(0, 3, 1, 2)\n",
    "labels_test = labels_test[indices]\n",
    "y_col_test, y_fire_test, y_steer_test = labels_test[:,0, :][:, :2], labels_test[:, 1, :], labels_test[:, 2, :][:, 0]\n",
    "y_col_test, y_fire_test, y_steer_test = torch.tensor(y_col_test), torch.tensor(y_fire_test), torch.tensor(y_steer_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_13752/2227258419.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('trained_model.pth'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TwoEE(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (ee_branch_binary): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (ee_branch_binary_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ee_branch_binary_fc): Linear(in_features=320000, out_features=1, bias=True)\n",
       "  (ee_branch_reg): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (ee_branch_reg_bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (ee_branch_reg_fc): Linear(in_features=320000, out_features=1, bias=True)\n",
       "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn5): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn6): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (binary_fc1): Linear(in_features=320000, out_features=256, bias=True)\n",
       "  (binary_fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       "  (regression_fc1): Linear(in_features=320000, out_features=256, bias=True)\n",
       "  (regression_fc2): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = TwoEE()\n",
    "model.load_state_dict(torch.load('trained_model.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the first strategy (only on th binary classification task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5157 [00:00<?, ?it/s]/tmp/ipykernel_13752/2516940954.py:32: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  sigmoide_cls1 = torch.sigmoid(logits_cls1) if not np.isnan(label_cls1).any() else None\n",
      "/tmp/ipykernel_13752/2516940954.py:33: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  pred_cls1 = (sigmoide_cls1 > 0.5).int() if not np.isnan(label_cls1).any() else None\n",
      "/tmp/ipykernel_13752/2516940954.py:35: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  sigmoide_cls2 = torch.sigmoid(logits_cls2) if not np.isnan(label_cls2).any() else None\n",
      "/tmp/ipykernel_13752/2516940954.py:36: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  pred_cls2 = (sigmoide_cls2 > 0.5).int() if not np.isnan(label_cls2).any() else None\n",
      "/tmp/ipykernel_13752/2516940954.py:39: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  pred_reg1 = logits_reg1.item() if not np.isnan(label_reg1).any() else None\n",
      "/tmp/ipykernel_13752/2516940954.py:40: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  pred_reg2 = logits_reg2.item() if not np.isnan(label_reg2).any() else None\n",
      "/tmp/ipykernel_13752/2516940954.py:43: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  if not np.isnan(label_cls1).any():\n",
      "/tmp/ipykernel_13752/2516940954.py:49: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  if not np.isnan(label_cls2).any():\n",
      "/tmp/ipykernel_13752/2516940954.py:57: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  if not np.isnan(label_cls1).any():\n",
      "/tmp/ipykernel_13752/2516940954.py:60: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  if not np.isnan(label_cls2).any():\n",
      "/tmp/ipykernel_13752/2516940954.py:63: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  if not np.isnan(label_reg1).any():\n",
      "/tmp/ipykernel_13752/2516940954.py:66: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  if not np.isnan(label_reg2).any():\n",
      " 14%|█▍        | 745/5157 [04:19<24:51,  2.96it/s]"
     ]
    }
   ],
   "source": [
    "def evaluar_modelo_con_confianza(modelo, entradas, labels_cls1, labels_cls2, labels_reg1, labels_reg2, umbral_range=np.arange(0.1, 1.0, 0.05)):\n",
    "    modelo.eval()  # Ponemos el modelo en modo evaluación\n",
    "    \n",
    "    # Listas para almacenar las métricas y las confianzas\n",
    "    all_pred_cls1 = []\n",
    "    all_pred_cls2 = []\n",
    "    all_pred_reg1 = []\n",
    "    all_pred_reg2 = []\n",
    "    \n",
    "    all_labels_cls1 = []\n",
    "    all_labels_cls2 = []\n",
    "    all_labels_reg1 = []\n",
    "    all_labels_reg2 = []\n",
    "    \n",
    "    confianza_cls1 = []\n",
    "    confianza_cls2 = []\n",
    "\n",
    "    # Recorremos las entradas una por una\n",
    "    for i in tqdm(range(len(entradas))):\n",
    "        input_data = entradas[i]\n",
    "        label_cls1 = labels_cls1[i]\n",
    "        label_cls2 = labels_cls2[i]\n",
    "        label_reg1 = labels_reg1[i]\n",
    "        label_reg2 = labels_reg2[i]\n",
    "        \n",
    "        # Hacemos la inferencia\n",
    "        with torch.no_grad():\n",
    "            logits_cls1, logits_reg1, logits_cls2, logits_reg2 = modelo(input_data.unsqueeze(0))  # Añadimos batch dimension\n",
    "        \n",
    "        \n",
    "        # Clasificación binaria (Sigmoide)\n",
    "        sigmoide_cls1 = torch.sigmoid(logits_cls1) if not np.isnan(label_cls1).any() else None\n",
    "        pred_cls1 = (sigmoide_cls1 > 0.5).int() if not np.isnan(label_cls1).any() else None\n",
    "\n",
    "        sigmoide_cls2 = torch.sigmoid(logits_cls2) if not np.isnan(label_cls2).any() else None\n",
    "        pred_cls2 = (sigmoide_cls2 > 0.5).int() if not np.isnan(label_cls2).any() else None\n",
    "        \n",
    "        # Regresión (sin transformación)\n",
    "        pred_reg1 = logits_reg1.item() if not np.isnan(label_reg1).any() else None\n",
    "        pred_reg2 = logits_reg2.item() if not np.isnan(label_reg2).any() else None\n",
    "        \n",
    "        # Métricas de confianza\n",
    "        if not np.isnan(label_cls1).any():\n",
    "            if sigmoide_cls1.item()>0.5:\n",
    "                confianza_cls1.append(sigmoide_cls1.item())\n",
    "            else:\n",
    "                confianza_cls1.append(1-sigmoide_cls1.item())\n",
    "        \n",
    "        if not np.isnan(label_cls2).any():\n",
    "            if sigmoide_cls2.item()>0.5:\n",
    "                confianza_cls2.append(sigmoide_cls2.item())\n",
    "            else:\n",
    "                confianza_cls2.append(1-sigmoide_cls2.item())\n",
    "\n",
    "        \n",
    "        # Almacenamos las predicciones y etiquetas\n",
    "        if not np.isnan(label_cls1).any():\n",
    "            all_pred_cls1.append(pred_cls1.item())\n",
    "            all_labels_cls1.append(np.argmax(label_cls1).item())  # Aplicamos argmax a la etiqueta binaria\n",
    "        if not np.isnan(label_cls2).any():\n",
    "            all_pred_cls2.append(pred_cls2.item())\n",
    "            all_labels_cls2.append(np.argmax(label_cls2).item())\n",
    "        if not np.isnan(label_reg1).any():\n",
    "            all_pred_reg1.append(pred_reg1)\n",
    "            all_labels_reg1.append(label_reg1.item())\n",
    "        if not np.isnan(label_reg2).any():\n",
    "            all_pred_reg2.append(pred_reg2)\n",
    "            all_labels_reg2.append(label_reg2.item())\n",
    "    \n",
    "    # Evaluamos las métricas por separado para cada tarea\n",
    "    \n",
    "    # Clasificación binaria\n",
    "    mask_cls1 = ~np.isnan(all_labels_cls1)\n",
    "    filtered_pred_cls1 = np.array(all_pred_cls1)[mask_cls1]\n",
    "    filtered_labels_cls1 = np.array(all_labels_cls1)[mask_cls1]\n",
    "    acc_cls1 = accuracy_score(filtered_labels_cls1, filtered_pred_cls1)\n",
    "\n",
    "    mask_cls2 = ~np.isnan(all_labels_cls2)\n",
    "    filtered_pred_cls2 = np.array(all_pred_cls2)[mask_cls2]\n",
    "    filtered_labels_cls2 = np.array(all_labels_cls2)[mask_cls2]\n",
    "    acc_cls2 = accuracy_score(filtered_labels_cls2, filtered_pred_cls2)\n",
    "    \n",
    "    # Regresión\n",
    "    mask_reg1 = ~np.isnan(all_labels_reg1)\n",
    "    filtered_pred_reg1 = np.array(all_pred_reg1)[mask_reg1]\n",
    "    filtered_labels_reg1 = np.array(all_labels_reg1)[mask_reg1]\n",
    "    mse_reg1 = mean_squared_error(filtered_labels_reg1, filtered_pred_reg1)\n",
    "\n",
    "    mask_reg2 = ~np.isnan(all_labels_reg2)\n",
    "    filtered_pred_reg2 = np.array(all_pred_reg2)[mask_reg2]\n",
    "    filtered_labels_reg2 = np.array(all_labels_reg2)[mask_reg2]\n",
    "    mse_reg2 = mean_squared_error(filtered_labels_reg2, filtered_pred_reg2)\n",
    "    \n",
    "    # Confianza promedio\n",
    "    confianza_prom_cls1 = np.mean(confianza_cls1) if len(confianza_cls1) > 0 else 0\n",
    "    confianza_prom_cls2 = np.mean(confianza_cls2) if len(confianza_cls2) > 0 else 0\n",
    "\n",
    "    # Determinamos el umbral de confianza óptimo para maximizar la precisión en la tarea 1\n",
    "    best_threshold = None\n",
    "    best_accuracy = -float('inf')\n",
    "    \n",
    "    # Asegurarnos de que estamos trabajando con las confidencias correctas\n",
    "    confidences = np.array(confianza_cls1)  # Usamos la confianza de la tarea 1 (puedes adaptarlo para otras tareas)\n",
    "    \n",
    "    for threshold in umbral_range:\n",
    "        # Aplicamos el umbral sobre las confidencias para obtener las predicciones binarias (1 o 0)\n",
    "        pred_cls1_thresh = (confidences > threshold).astype(int)  # Se compara la confianza con el umbral\n",
    "        \n",
    "        # Filtramos las etiquetas y las predicciones que tienen confianza sobre el umbral\n",
    "        mask = confidences > threshold\n",
    "        filtered_pred_cls1_thresh = filtered_pred_cls1[mask]\n",
    "        filtered_labels_cls1_thresh = filtered_labels_cls1[mask]\n",
    "        current_len = 0\n",
    "        \n",
    "        # Calculamos el accuracy solo para las instancias donde hay etiquetas válidas\n",
    "        if len(filtered_labels_cls1_thresh) > 0:  # Asegurarse de que hay datos para calcular el accuracy\n",
    "            acc = accuracy_score(filtered_labels_cls1_thresh, filtered_pred_cls1_thresh)\n",
    "        \n",
    "            # Si encontramos un umbral mejor, lo guardamos\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_threshold = threshold\n",
    "                current_len = len(filtered_labels_cls1_thresh)\n",
    "                best_mask = mask\n",
    "    \n",
    "    acc_final = accuracy_score(filtered_labels_cls2[~best_mask], filtered_pred_cls2[~best_mask])\n",
    "\n",
    "    # Mostrar resultados\n",
    "    print(f'Precisión clasificación binaria ee: {acc_cls1:.4f}')\n",
    "    print(f'Precisión clasificación binaria normal: {acc_cls2:.4f}')\n",
    "    print(f'Error cuadrático medio (MSE) en regresión ee: {mse_reg1:.4f}')\n",
    "    print(f'Error cuadrático medio (MSE) en regresión normal: {mse_reg2:.4f}')\n",
    "    \n",
    "    # Confianza\n",
    "    print(f'Confianza promedio (cls1): {confianza_prom_cls1:.4f}')\n",
    "    print(f'Confianza promedio (cls2): {confianza_prom_cls2:.4f}')\n",
    "    \n",
    "    # Mejor umbral para la tarea 1\n",
    "    print(f'El mejor umbral de confianza para tarea 1 es: {best_threshold:.4f}')\n",
    "    print(f'Con ese umbral, la precisión es: {best_accuracy:.4f}')\n",
    "\n",
    "    return {'acc_cls1': acc_cls1, 'acc_cls2': acc_cls2, 'mse_reg1': mse_reg1, 'mse_reg2': mse_reg2, 'best_threshold': best_threshold, 'best_accuracy': best_accuracy, 'proportion where threshold is applied': current_len/len(filtered_pred_cls1), 'acc on cls2 w/ ee': acc_final}\n",
    "\n",
    "# Llamada a la función de evaluación\n",
    "metrics = evaluar_modelo_con_confianza(model, images_test, y_col_test, y_col_test, y_steer_test, y_steer_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc_cls1': 0.8798498122653317,\n",
       " 'acc_cls2': 0.9236545682102628,\n",
       " 'mse_reg1': np.float64(0.011940631447059893),\n",
       " 'mse_reg2': np.float64(0.05897579385018556),\n",
       " 'best_threshold': np.float64(0.9500000000000003),\n",
       " 'best_accuracy': 0.9192634560906515,\n",
       " 'proportion where threshold is applied': 0.8836045056320401,\n",
       " 'acc on cls2 w/ ee': 0.8279569892473119}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy on collision task: 0.9086\n",
      "Maximum accuracy that could be achieved: 0.9237\n"
     ]
    }
   ],
   "source": [
    "# overall accuracy on collision task\n",
    "acc_task = metrics['acc on cls2 w/ ee']* (1-metrics['proportion where threshold is applied']) + metrics['best_accuracy']*metrics['proportion where threshold is applied']\n",
    "print(f'Overall accuracy on collision task: {acc_task:.4f}')\n",
    "print(f'Maximum accuracy that could be achieved: {metrics[\"acc_cls2\"]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aproximate MSE on regression task: 0.0174\n"
     ]
    }
   ],
   "source": [
    "# meanwhile, the mse on the regression task is\n",
    "print(f'Aproximate MSE on regression task: {metrics[\"mse_reg1\"]*metrics['proportion where threshold is applied']+metrics['mse_reg2']*(1-metrics['proportion where threshold is applied']):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 200, 200]             320\n",
      "       BatchNorm2d-2         [-1, 32, 200, 200]              64\n",
      "            Conv2d-3         [-1, 64, 200, 200]          18,496\n",
      "       BatchNorm2d-4         [-1, 64, 200, 200]             128\n",
      "         MaxPool2d-5         [-1, 64, 100, 100]               0\n",
      "            Conv2d-6        [-1, 128, 100, 100]          73,856\n",
      "       BatchNorm2d-7        [-1, 128, 100, 100]             256\n",
      "            Conv2d-8        [-1, 256, 100, 100]         295,168\n",
      "       BatchNorm2d-9        [-1, 256, 100, 100]             512\n",
      "        MaxPool2d-10          [-1, 256, 50, 50]               0\n",
      "           Conv2d-11          [-1, 128, 50, 50]         295,040\n",
      "      BatchNorm2d-12          [-1, 128, 50, 50]             256\n",
      "           Linear-13                    [-1, 1]         320,001\n",
      "           Conv2d-14          [-1, 128, 50, 50]         295,040\n",
      "      BatchNorm2d-15          [-1, 128, 50, 50]             256\n",
      "           Linear-16                    [-1, 1]         320,001\n",
      "           Conv2d-17          [-1, 512, 50, 50]       1,180,160\n",
      "      BatchNorm2d-18          [-1, 512, 50, 50]           1,024\n",
      "           Conv2d-19          [-1, 512, 50, 50]       2,359,808\n",
      "      BatchNorm2d-20          [-1, 512, 50, 50]           1,024\n",
      "        MaxPool2d-21          [-1, 512, 25, 25]               0\n",
      "           Linear-22                  [-1, 256]      81,920,256\n",
      "           Linear-23                    [-1, 1]             257\n",
      "           Linear-24                  [-1, 256]      81,920,256\n",
      "           Linear-25                    [-1, 1]             257\n",
      "================================================================\n",
      "Total params: 169,002,436\n",
      "Trainable params: 169,002,436\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.15\n",
      "Forward/backward pass size (MB): 178.23\n",
      "Params size (MB): 644.69\n",
      "Estimated Total Size (MB): 823.07\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, (1, 200, 200))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Half of the model is deactivated in case the early exit is taken. Concretely, from Conv2d-17 to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_macs_deact = 1180160+1024+2359808+1024+81920256+257+81920256+257"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over 100 inferences, aprox 1948263192.24 MACs will be saved\n",
      "Which represents a 88.47% discount over the full model\n"
     ]
    }
   ],
   "source": [
    "# over 100 inferences\n",
    "\n",
    "num_discount =( 1 - metrics['proportion where threshold is applied']) * num_macs_deact * 100\n",
    "print(f\"Over 100 inferences, aprox {num_discount:.2f} MACs will be saved\")\n",
    "\n",
    "print(f'Which represents a {(169002436 * 100 - num_discount)/(169002436*100)*100:.2f}% discount over the full model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With the second strategy, evaluating also confidence on regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluar_modelo_con_confianza(modelo, entradas, labels_cls1, labels_cls2, labels_reg1, labels_reg2, umbral_range=np.arange(0.1, 1.0, 0.05)):\n",
    "    modelo.eval()  # Ponemos el modelo en modo evaluación\n",
    "    \n",
    "    # Listas para almacenar las métricas y las confianzas\n",
    "    all_pred_cls1 = []\n",
    "    all_pred_cls2 = []\n",
    "    all_pred_reg1 = []\n",
    "    all_pred_reg2 = []\n",
    "    \n",
    "    all_labels_cls1 = []\n",
    "    all_labels_cls2 = []\n",
    "    all_labels_reg1 = []\n",
    "    all_labels_reg2 = []\n",
    "    \n",
    "    confianza_cls1 = []\n",
    "    confianza_cls2 = []\n",
    "\n",
    "    # Recorremos las entradas una por una\n",
    "    for i in tqdm(range(len(entradas))):\n",
    "        input_data = entradas[i]\n",
    "        label_cls1 = labels_cls1[i]\n",
    "        label_cls2 = labels_cls2[i]\n",
    "        label_reg1 = labels_reg1[i]\n",
    "        label_reg2 = labels_reg2[i]\n",
    "        \n",
    "        # Hacemos la inferencia\n",
    "        with torch.no_grad():\n",
    "            logits_cls1, logits_reg1, logits_cls2, logits_reg2 = modelo(input_data.unsqueeze(0))  # Añadimos batch dimension\n",
    "        \n",
    "        \n",
    "        # Clasificación binaria (Sigmoide)\n",
    "        sigmoide_cls1 = torch.sigmoid(logits_cls1) if not np.isnan(label_cls1).any() else None\n",
    "        pred_cls1 = (sigmoide_cls1 > 0.5).int() if not np.isnan(label_cls1).any() else None\n",
    "\n",
    "        sigmoide_cls2 = torch.sigmoid(logits_cls2) if not np.isnan(label_cls2).any() else None\n",
    "        pred_cls2 = (sigmoide_cls2 > 0.5).int() if not np.isnan(label_cls2).any() else None\n",
    "        \n",
    "        # Regresión (sin transformación)\n",
    "        pred_reg1 = logits_reg1.item() if not np.isnan(label_reg1).any() else None\n",
    "        pred_reg2 = logits_reg2.item() if not np.isnan(label_reg2).any() else None\n",
    "        \n",
    "        # Métricas de confianza\n",
    "        if not np.isnan(label_cls1).any():\n",
    "            if sigmoide_cls1.item()>0.5:\n",
    "                confianza_cls1.append(sigmoide_cls1.item())\n",
    "            else:\n",
    "                confianza_cls1.append(1-sigmoide_cls1.item())\n",
    "        \n",
    "        if not np.isnan(label_cls2).any():\n",
    "            if sigmoide_cls2.item()>0.5:\n",
    "                confianza_cls2.append(sigmoide_cls2.item())\n",
    "            else:\n",
    "                confianza_cls2.append(1-sigmoide_cls2.item())\n",
    "\n",
    "        \n",
    "        # Almacenamos las predicciones y etiquetas\n",
    "        if not np.isnan(label_cls1).any():\n",
    "            all_pred_cls1.append(pred_cls1.item())\n",
    "            all_labels_cls1.append(np.argmax(label_cls1).item())  # Aplicamos argmax a la etiqueta binaria\n",
    "        if not np.isnan(label_cls2).any():\n",
    "            all_pred_cls2.append(pred_cls2.item())\n",
    "            all_labels_cls2.append(np.argmax(label_cls2).item())\n",
    "        if not np.isnan(label_reg1).any():\n",
    "            all_pred_reg1.append(pred_reg1)\n",
    "            all_labels_reg1.append(label_reg1.item())\n",
    "        if not np.isnan(label_reg2).any():\n",
    "            all_pred_reg2.append(pred_reg2)\n",
    "            all_labels_reg2.append(label_reg2.item())\n",
    "    \n",
    "    # Evaluamos las métricas por separado para cada tarea\n",
    "    \n",
    "    # Clasificación binaria\n",
    "    mask_cls1 = ~np.isnan(all_labels_cls1)\n",
    "    filtered_pred_cls1 = np.array(all_pred_cls1)[mask_cls1]\n",
    "    filtered_labels_cls1 = np.array(all_labels_cls1)[mask_cls1]\n",
    "    acc_cls1 = accuracy_score(filtered_labels_cls1, filtered_pred_cls1)\n",
    "\n",
    "    mask_cls2 = ~np.isnan(all_labels_cls2)\n",
    "    filtered_pred_cls2 = np.array(all_pred_cls2)[mask_cls2]\n",
    "    filtered_labels_cls2 = np.array(all_labels_cls2)[mask_cls2]\n",
    "    acc_cls2 = accuracy_score(filtered_labels_cls2, filtered_pred_cls2)\n",
    "    \n",
    "    # Regresión\n",
    "    mask_reg1 = ~np.isnan(all_labels_reg1)\n",
    "    filtered_pred_reg1 = np.array(all_pred_reg1)[mask_reg1]\n",
    "    filtered_labels_reg1 = np.array(all_labels_reg1)[mask_reg1]\n",
    "    mse_reg1 = mean_squared_error(filtered_labels_reg1, filtered_pred_reg1)\n",
    "\n",
    "    mask_reg2 = ~np.isnan(all_labels_reg2)\n",
    "    filtered_pred_reg2 = np.array(all_pred_reg2)[mask_reg2]\n",
    "    filtered_labels_reg2 = np.array(all_labels_reg2)[mask_reg2]\n",
    "    mse_reg2 = mean_squared_error(filtered_labels_reg2, filtered_pred_reg2)\n",
    "    \n",
    "    # Confianza promedio\n",
    "    confianza_prom_cls1 = np.mean(confianza_cls1) if len(confianza_cls1) > 0 else 0\n",
    "    confianza_prom_cls2 = np.mean(confianza_cls2) if len(confianza_cls2) > 0 else 0\n",
    "\n",
    "    # Determinamos el umbral de confianza óptimo para maximizar la precisión en la tarea 1\n",
    "    best_threshold = None\n",
    "    best_accuracy = -float('inf')\n",
    "    \n",
    "    # Asegurarnos de que estamos trabajando con las confidencias correctas\n",
    "    confidences = np.array(confianza_cls1)  # Usamos la confianza de la tarea 1 (puedes adaptarlo para otras tareas)\n",
    "    \n",
    "    for threshold in umbral_range:\n",
    "        # Aplicamos el umbral sobre las confidencias para obtener las predicciones binarias (1 o 0)\n",
    "        pred_cls1_thresh = (confidences > threshold).astype(int)  # Se compara la confianza con el umbral\n",
    "        \n",
    "        # Filtramos las etiquetas y las predicciones que tienen confianza sobre el umbral\n",
    "        mask = confidences > threshold\n",
    "        filtered_pred_cls1_thresh = filtered_pred_cls1[mask]\n",
    "        filtered_labels_cls1_thresh = filtered_labels_cls1[mask]\n",
    "        current_len = 0\n",
    "        \n",
    "        # Calculamos el accuracy solo para las instancias donde hay etiquetas válidas\n",
    "        if len(filtered_labels_cls1_thresh) > 0:  # Asegurarse de que hay datos para calcular el accuracy\n",
    "            acc = accuracy_score(filtered_labels_cls1_thresh, filtered_pred_cls1_thresh)\n",
    "        \n",
    "            # Si encontramos un umbral mejor, lo guardamos\n",
    "            if acc > best_accuracy:\n",
    "                best_accuracy = acc\n",
    "                best_threshold = threshold\n",
    "                current_len = len(filtered_labels_cls1_thresh)\n",
    "                best_mask = mask\n",
    "    \n",
    "    acc_final = accuracy_score(filtered_labels_cls2[~best_mask], filtered_pred_cls2[~best_mask])\n",
    "\n",
    "\n",
    "\n",
    "    best_threshold_reg = None\n",
    "    best_mse = float('inf')\n",
    "\n",
    "    error_model = joblib.load('lasso.pkl')\n",
    "    X = np.array(entradas).squeeze(1)\n",
    "    X = X.view(X.size(0), -1)\n",
    "    X = np.hstack([X, np.array(all_pred_reg1).reshape(-1, 1)])\n",
    "    confidences_reg = error_model.predict(X)\n",
    "\n",
    "    for threshold in umbral_range:\n",
    "        pred_reg1_thresh = (confidences_reg > threshold).astype(int)\n",
    "\n",
    "        mask = confidences_reg > threshold\n",
    "        filtered_pred_reg1_thresh = filtered_pred_reg1[mask]\n",
    "        filtered_labels_reg1_thresh = filtered_labels_reg1[mask]\n",
    "        current_len_reg = 0\n",
    "\n",
    "        if len(filtered_labels_reg1_thresh) > 0:\n",
    "            mse = mean_squared_error(filtered_labels_reg1_thresh, filtered_pred_reg1_thresh)\n",
    "\n",
    "            if mse < best_mse:\n",
    "                best_mse = mse\n",
    "                best_threshold_reg = threshold\n",
    "                current_len_reg = len(filtered_labels_reg1_thresh)\n",
    "                best_mask_reg = mask\n",
    "\n",
    "    mse_final = mean_squared_error(filtered_labels_reg2[~best_mask_reg], filtered_pred_reg2[~best_mask_reg])\n",
    "\n",
    "    \n",
    "\n",
    "    # Mostrar resultados\n",
    "    print(f'Precisión clasificación binaria ee: {acc_cls1:.4f}')\n",
    "    print(f'Precisión clasificación binaria normal: {acc_cls2:.4f}')\n",
    "    print(f'Error cuadrático medio (MSE) en regresión ee: {mse_reg1:.4f}')\n",
    "    print(f'Error cuadrático medio (MSE) en regresión normal: {mse_reg2:.4f}')\n",
    "    \n",
    "    # Confianza\n",
    "    print(f'Confianza promedio (cls1): {confianza_prom_cls1:.4f}')\n",
    "    print(f'Confianza promedio (cls2): {confianza_prom_cls2:.4f}')\n",
    "    \n",
    "    # Mejor umbral para la tarea 1\n",
    "    print(f'El mejor umbral de confianza para tarea 1 es: {best_threshold:.4f}')\n",
    "    print(f'Con ese umbral, la precisión es: {best_accuracy:.4f}')\n",
    "\n",
    "    return {'acc_cls1': acc_cls1, 'acc_cls2': acc_cls2, 'mse_reg1': mse_reg1, 'mse_reg2': mse_reg2, 'best_threshold': best_threshold, 'best_accuracy': best_accuracy, 'proportion where threshold is applied': current_len/len(filtered_pred_cls1),\n",
    "             'acc on cls2 w/ ee': acc_final, 'best_threshold_reg': best_threshold_reg, 'best_mse': best_mse, 'proportion where threshold is applied_reg': current_len_reg/len(filtered_pred_reg1), 'mse on cls2 w/ ee': mse_final}\n",
    "\n",
    "# Llamada a la función de evaluación\n",
    "metrics = evaluar_modelo_con_confianza(model, images_test, y_col_test, y_col_test, y_steer_test, y_steer_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
