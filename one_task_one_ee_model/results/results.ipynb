{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle as pkl\n",
    "import os\n",
    "from tensorflow.keras.utils import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import onnxruntime as ort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qat_size = os.path.getsize('model_qat.onnx')/(1024**2)\n",
    "model_ptq_size = os.path.getsize('model_ptq.onnx')/(1024**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model QAT size: 0.42 MB\n",
      "Model PTQ size: 0.42 MB\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model QAT size: {model_qat_size:.2f} MB\")\n",
    "print(f\"Model PTQ size: {model_ptq_size:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_creator(path_to_folder, max_by_experiment = 3):\n",
    "    fire = 0\n",
    "    images_ptq, images_qat, labels = [], [], []\n",
    "\n",
    "\n",
    "    for folder in os.listdir(path_to_folder):\n",
    "\n",
    "        if os.path.isdir(os.path.join(path_to_folder, folder)):\n",
    "\n",
    "            for file in os.listdir(os.path.join(path_to_folder, folder)):\n",
    "\n",
    "                if file.endswith('.txt'):\n",
    "\n",
    "                    if 'fire' in file and fire < max_by_experiment:\n",
    "                        fire += 1\n",
    "                        for pic in sorted(os.listdir(os.path.join(path_to_folder, folder, 'images'))):\n",
    "                            img = load_img(os.path.join(os.path.join(path_to_folder, folder, 'images'), pic), target_size=(200, 200), color_mode='grayscale')  # Ajustar tamaÃ±o y modo de color\n",
    "                            img_array = img_to_array(img) / 128.0  -1 # Normalizar la imagen\n",
    "                            images_ptq.append(img_array)\n",
    "                            img_array = img_to_array(img) / 255.0\n",
    "                            images_qat.append(img_array)\n",
    "\n",
    "                        \n",
    "                        labels_txt = np.loadtxt(os.path.join(path_to_folder, folder, file), delimiter=' ')\n",
    "\n",
    "                        for label in labels_txt:\n",
    "                            label = [np.array([np.nan]*2), label, np.array([np.nan])]\n",
    "                            label = pad_sequences(label, dtype='float32', padding='post', value=np.nan)\n",
    "                            labels.append(label)\n",
    "\n",
    "\n",
    "\n",
    "    return np.array(images_ptq), np.array(images_qat), np.array(labels)\n",
    "\n",
    "images_test_ptq, images_test_qat, labels_test = dataset_creator('../../testing', 20)\n",
    "indices = np.random.permutation(images_test_ptq.shape[0])\n",
    "images_test_ptq = images_test_ptq[indices]\n",
    "images_test_qat = images_test_qat[indices]\n",
    "labels_test = labels_test[indices]\n",
    "_, y_fire_test, _ = labels_test[:,0, :][:, :2], labels_test[:, 1, :], labels_test[:, 2, :][:, 0]\n",
    "\n",
    "images_test_ptq = images_test_ptq.reshape(images_test_ptq.shape[0], 1, 200, 200)\n",
    "images_test_qat = images_test_qat.reshape(images_test_qat.shape[0], 1, 200, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_qat = ort.InferenceSession('model_qat.onnx')\n",
    "model_ptq = ort.InferenceSession('model_ptq.onnx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "outs_qat = [out.name for out in model_qat.get_outputs()]\n",
    "outs_ptq = [out.name for out in model_ptq.get_outputs()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_qat = []\n",
    "predictions_ptq = []\n",
    "\n",
    "for i in range(images_test_ptq.shape[0]):\n",
    "    input_data_ptq = [images_test_ptq[i]]\n",
    "    input_data_qat = [images_test_qat[i]]\n",
    "    pred_qat = model_qat.run(outs_qat, {'input': input_data_qat})\n",
    "    pred_ptq = model_ptq.run(outs_ptq, {'input': input_data_ptq})\n",
    "    predictions_qat.append(pred_qat)\n",
    "    predictions_ptq.append(pred_ptq)\n",
    "\n",
    "predictions_qat_ee = np.squeeze(np.argmax(predictions_qat, axis=-1), axis=-1)[:, 0]\n",
    "predictions_qat_final = np.squeeze(np.argmax(predictions_qat, axis=-1), axis=-1)[:, 1]\n",
    "predictions_ptq_ee = np.squeeze(np.argmax(predictions_ptq, axis=-1), axis=-1)[:, 0]\n",
    "predictions_ptq_final = np.squeeze(np.argmax(predictions_ptq, axis=-1), axis=-1)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy QAT early exit: 0.70\n",
      "Accuracy PTQ early exit: 0.74\n",
      "Accuracy QAT: 0.69\n",
      "Accuracy PTQ: 0.76\n"
     ]
    }
   ],
   "source": [
    "labels_class = np.argmax(y_fire_test, axis=-1)\n",
    "\n",
    "acc_qat_ee = accuracy_score(labels_class, predictions_qat_ee)\n",
    "acc_ptq_ee = accuracy_score(labels_class, predictions_ptq_ee)\n",
    "\n",
    "acc_qat = accuracy_score(labels_class, predictions_qat_final)\n",
    "acc_ptq = accuracy_score(labels_class, predictions_ptq_final)\n",
    "\n",
    "print(f\"Accuracy QAT early exit: {acc_qat_ee:.2f}\")\n",
    "print(f\"Accuracy PTQ early exit: {acc_ptq_ee:.2f}\")\n",
    "\n",
    "print(f\"Accuracy QAT: {acc_qat:.2f}\")\n",
    "print(f\"Accuracy PTQ: {acc_ptq:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'QAT': [acc_qat_ee, acc_qat], 'PTQ': [acc_ptq_ee, acc_ptq]}, index=['Early Exit', 'Final']).to_csv('performance_table.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report QAT, early exit:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.52      0.50      2127\n",
      "           1       0.58      0.73      0.65      1278\n",
      "           2       0.82      0.69      0.75      4059\n",
      "           3       0.79      0.86      0.82      2420\n",
      "\n",
      "    accuracy                           0.70      9884\n",
      "   macro avg       0.67      0.70      0.68      9884\n",
      "weighted avg       0.71      0.70      0.70      9884\n",
      " \n",
      "\n",
      "\n",
      "Classification report QAT:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.51      0.50      2127\n",
      "           1       0.52      0.69      0.59      1278\n",
      "           2       0.81      0.69      0.74      4059\n",
      "           3       0.80      0.84      0.82      2420\n",
      "\n",
      "    accuracy                           0.69      9884\n",
      "   macro avg       0.66      0.68      0.66      9884\n",
      "weighted avg       0.70      0.69      0.69      9884\n",
      " \n",
      "\n",
      "\n",
      "Classification report PTQ, early exit:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.58      0.58      2127\n",
      "           1       0.59      0.75      0.66      1278\n",
      "           2       0.86      0.74      0.79      4059\n",
      "           3       0.80      0.86      0.83      2420\n",
      "\n",
      "    accuracy                           0.74      9884\n",
      "   macro avg       0.71      0.73      0.72      9884\n",
      "weighted avg       0.75      0.74      0.74      9884\n",
      " \n",
      "\n",
      "\n",
      "Classification report PTQ:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.56      0.60      2127\n",
      "           1       0.60      0.81      0.68      1278\n",
      "           2       0.88      0.78      0.82      4059\n",
      "           3       0.81      0.90      0.85      2420\n",
      "\n",
      "    accuracy                           0.76      9884\n",
      "   macro avg       0.73      0.76      0.74      9884\n",
      "weighted avg       0.77      0.76      0.76      9884\n",
      " \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification report QAT, early exit:\\n\")\n",
    "print(classification_report(labels_class, predictions_qat_ee), '\\n\\n')\n",
    "\n",
    "print(\"Classification report QAT:\\n\")\n",
    "print(classification_report(labels_class, predictions_qat_final), '\\n\\n')\n",
    "\n",
    "print(\"Classification report PTQ, early exit:\\n\")\n",
    "print(classification_report(labels_class, predictions_ptq_ee), '\\n\\n')\n",
    "\n",
    "print(\"Classification report PTQ:\\n\")\n",
    "print(classification_report(labels_class, predictions_ptq_final), '\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
